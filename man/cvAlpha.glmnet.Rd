% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/cvAlpha.r
\name{cvAlpha.glmnet}
\alias{cvAlpha.glmnet}
\alias{cvAlpha.glmnet.default}
\alias{cvAlpha.glmnet.formula}
\title{Do elastic net cross-validation for alpha and lambda simultaneously}
\usage{
cvAlpha.glmnet(x, ...)

\method{cvAlpha.glmnet}{default}(x, y, alpha = seq(0, 1, len = 11)^3,
  nfolds = 10, ..., outerParallel = NULL, checkInnerParallel = TRUE)

\method{cvAlpha.glmnet}{formula}(formula, data, ..., weights, offset = NULL,
  subset = NULL, na.action = na.omit, drop.unused.levels = FALSE,
  xlev = NULL, sparse = FALSE)
}
\arguments{
\item{x}{A matrix of predictor variables.}

\item{...}{Other arguments to be passed to \code{cv.glmnet}.}

\item{y}{A response vector or matrix (for a multinomial response).}

\item{alpha}{A vector of alpha values for which to do cross-validation. The default is a sequence of 11 values more closely spaced around alpha = 0.}

\item{nfolds}{The number of cross-validation folds to use. Defaults to 10.}

\item{outerParallel}{Method of parallelising the outer loop over alpha. See 'Details' below. If \code{NULL}, the loop is run sequentially.}

\item{checkInnerParallel}{If the outer loop is run in parallel, check that the inner loop over lambda will not be in contention for cores.}

\item{formula}{A model formula; interaction terms are allowed and will be expanded per the usual rules for linear models.}

\item{data}{A data frame or matrix containing the variables in the formula.}

\item{weights}{An optional vector of case weights to be used in the fitting process. If missing, defaults to an unweighted fit.}

\item{offset}{An optional vector of offsets, an \emph{a priori} known component to be included in the linear predictor.}

\item{subset}{An optional vector specifying the subset of observations to be used to fit the model.}

\item{na.action}{A function which indicates what should happen when the data contain \code{NA}s.}

\item{drop.unused.levels}{Should factors have unused levels dropped? Defaults to \code{FALSE}.}

\item{xlev}{A named list of character vectors giving the full set of levels to be assumed for each factor.}

\item{sparse}{Should the model matrix be in sparse format? This can save memory when dealing with many factor variables, each with many levels (but see the warning below).}
}
\description{
Do elastic net cross-validation for alpha and lambda simultaneously
}
\details{
The \code{cvAlpha.glmnet} function does simultaneous cross-validation for both the alpha and lambda parameters in an elastic net model. It follows the procedure outlined in the documentation for \code{\link[glmnet:cv.glmnet]{glmnet::cv.glmnet}}: it creates a vector \code{foldid} allocating the observations into folds, and then calls \code{cv.glmnet} in a loop over different values of alpha, but the same values of \code{foldid} each time.

Optionally this loop over alpha can be parallelised; currently, \code{cvAlpha.glmnet} knows about two methods of doing so:
\itemize{
  \item Via \code{\link{parLapply}} in the \code{parallel} package. To use this, set \code{outerParallel} to a valid cluster object created by \code{\link{makeCluster}}.
  \item Via \code{\link{rxExec}} as supplied by Revolution Analytics' \code{RevoScaleR} package. To use this, set \code{outerParallel} to a valid compute context created by \code{\link{RxComputeContext}}, or a character string specifying such a context.
}
If the outer loop is run in parallel, \code{cvAlpha.glmnet} can check if the inner loop (over lambda) is also set to run in parallel, and disable this if it would lead to contention for cores. This is done if it is likely that the parallelisation is local on a multicore machine, ie if \code{outerParallel} is a \code{SOCKcluster} object running on \code{"localhost"}, or if the supplied compute context is local parallel.

The formula method works in a similar manner to \code{lm}, \code{glm} and other modelling functions. The arguments are used to generate a \emph{model frame}, which is a data frame augmented with information about the roles the columns play in fitting the model. This is then turned into a \emph{model matrix} and a response vector, which are passed to \code{glmnet::glmnet} along with any arguments in \code{...}. If \code{sparse} is TRUE, then \code{Matrix::sparse.model.matrix} is used instead of \code{stats::model.matrix} to create the model matrix.
}
\section{Value}{

For \code{cvAlpha.glmnet.default}, an object of class \code{cvAlpha.glmnet}. This is a list containing the following:
\itemize{
  \item \code{alpha} The vector of alpha values
  \item \code{nfolds} The number of folds
  \item \code{modlist} A list of \code{cv.glmnet} objects, containing the cross-validation results for each value of alpha
}
The function \code{cvAlpha.glmnet.formula} adds a few more components to the above, to facilitate working with formulas.
}

\section{Warning}{

Fundamental to R's handling of formulas, model frames and model matrices is a \code{\link{terms}} object, which encodes how variables and their interactions (if any) are organised. One of the attributes of this object is a matrix with one row per variable, and one column per main effect and interaction. Thus, at minimum, this is (approximately) a \eqn{p \times p}{p x p} square matrix where \eqn{p} is the number of main effects in the model. When \eqn{p ~ 16000}, this matrix will be about a gigabyte in size. Because of this, you should use the formula interface with caution when working with wide datasets and limited memory.
}
\examples{
cvAlpha.glmnet(mpg ~ ., data=mtcars)

\dontrun{

# Leukemia example dataset from Trevor Hastie's website
download.file("http://web.stanford.edu/~hastie/glmnet/glmnetData/Leukemia.RData",
              "Leukemia.RData")
load("Leukemia.Rdata")
leuk <- do.call(data.frame, Leukemia)
cvAlpha.glmnet(y ~ ., leuk, family="binomial")
}
}
\seealso{
\code{\link[glmnet:cv.glmnet]{glmnet::cv.glmnet}}
}

